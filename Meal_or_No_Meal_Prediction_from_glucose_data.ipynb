{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Meal_or_No_Meal_Prediction_from_glucose_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUc840MxyHclDFP/fuZNaH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrish39/Machine-learning-notebooks/blob/main/Meal_or_No_Meal_Prediction_from_glucose_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHPYLFPqMbuu"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "import scipy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression as lm\n",
        "import plotly.graph_objs as go\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndYtMnntOu-2"
      },
      "source": [
        "def kfoldCrossValidation(trainedModel, X, y):\n",
        "    cv = KFold(n_splits=5, random_state=3, shuffle=True)\n",
        "    scores = []\n",
        "    for train_index, test_index in cv.split(X):\n",
        "        X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
        "        trainedModel.fit(X_train, np.ravel(y_train))\n",
        "        scores.append(trainedModel.score(X_test, y_test))\n",
        "\n",
        "    print(\"KFold Scores\",scores)\n",
        "    print(\"Kfold Mean Score -->\",np.mean(scores))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUyQ-bMmOyxE"
      },
      "source": [
        "def classificationReport(y_test, predictedLabels):\n",
        "    from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "    print(confusion_matrix(y_test,predictedLabels.round()))\n",
        "    print(classification_report(y_test,predictedLabels.round()))\n",
        "    print(accuracy_score(y_test, predictedLabels.round())) "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0Jipq5FO0_e"
      },
      "source": [
        "def RandomForestClassifier(X, y, X_train, X_test, y_train, y_test):\n",
        "    print('***************','RandomForestClassifier','***************')\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    clf = RandomForestClassifier(\n",
        "        bootstrap=True,\n",
        "        max_depth=5,\n",
        "        max_features='sqrt',\n",
        "        min_samples_leaf=4,\n",
        "        min_samples_split=10,\n",
        "        n_estimators=800\n",
        "    )\n",
        "    rf = clf.fit(X, np.ravel(y))\n",
        "    score = rf.score(X_test, y_test)\n",
        "    y_pred = rf.predict(X_test) \n",
        "\n",
        "    #Accuracy Report\n",
        "    classificationReport(y_test, y_pred)               \n",
        "    \n",
        "    #KFold Cross Validation\n",
        "    kfoldCrossValidation(rf, X, y)\n",
        "    trainedModelFilename = \"trainedModel.pkl\"\n",
        "    with open(trainedModelFilename, 'wb') as file:\n",
        "        pickle.dump(rf, file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0PdN5NLO4GF"
      },
      "source": [
        "def DecisionTreeClassifier(X, y, X_train, X_test, y_train, y_test):\n",
        "    print('***************','DecisionTreeClassifier','***************')\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    clf = DecisionTreeClassifier(max_depth=1)\n",
        "    clf = clf.fit(X_train, y_train)\n",
        "    score = clf.score(X_test, y_test)\n",
        "    \n",
        "    predictedLabels = clf.predict(X_test)\n",
        "    classificationReport(y_test, predictedLabels)\n",
        "\n",
        "    kfoldCrossValidation(clf, X, y)\n",
        "    trainedModelFilename = \"trainedModel.pkl\"\n",
        "    with open(trainedModelFilename, 'wb') as file:\n",
        "        pickle.dump(clf, file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4PUCY2eO6Qr"
      },
      "source": [
        "def MultiLayerPerceptron(X, y, X_train, X_test, y_train, y_test):\n",
        "    print('***************','MultiLayerPerceptron','***************')\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    clf = MLPClassifier(hidden_layer_sizes=1000,activation='logistic',alpha=1,learning_rate='invscaling')\n",
        "    clf.fit(X_train, np.ravel(y_train))\n",
        "    score = clf.score(X_test, y_test)\n",
        "\n",
        "    predictedLabels = clf.predict(X_test)\n",
        "    classificationReport(y_test, predictedLabels)\n",
        "\n",
        "    kfoldCrossValidation(clf, X, y)\n",
        "    trainedModelFilename = \"trainedModel.pkl\"\n",
        "    with open(trainedModelFilename, 'wb') as file:\n",
        "        pickle.dump(clf, file)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kjgI2ZDO8xg"
      },
      "source": [
        "def PCA(featureMatrix):\n",
        "    from sklearn.decomposition import PCA\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    featureMatrix = StandardScaler().fit_transform(featureMatrix)\n",
        "    pca = PCA(n_components=6)\n",
        "    principalComponents = pca.fit(featureMatrix)\n",
        "    transformedPrincipalComponent = pca.fit_transform(featureMatrix)\n",
        "\n",
        "    finalPrincipalComponents = pd.DataFrame(data=transformedPrincipalComponent, columns = ['PC1', 'PC2','PC3', 'PC4','PC5', 'PC6'])\n",
        "\n",
        "    return finalPrincipalComponents"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpEL04aLPa9L"
      },
      "source": [
        "mealDataCsv = sorted(glob.glob(\"./MealNoMealData/*.csv\"))\n",
        "cols = list(range(0,31)) #Assuming the max of columns will be 30\n",
        "labelColumn = []\n",
        "mealNoMealDataFrame = pd.DataFrame()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaPcj1CmQLb4"
      },
      "source": [
        "temp = pd.DataFrame()\n",
        "    \n",
        "# Constructing the dataset in such a way that there will not be bias while KFold\n",
        "# 5 No-meal 5 Meal continuosly\n",
        "for i in range(0, 50):\n",
        "    for file in mealDataCsv:\n",
        "        temp = pd.DataFrame(pd.read_csv(file, names=cols))\n",
        "        mealNoMealDataFrame = mealNoMealDataFrame.append(pd.DataFrame(np.array(temp.iloc[[i]])))\n",
        "mealNoMealDataFrameArray = mealNoMealDataFrame.to_numpy()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfsKM80-QSHA"
      },
      "source": [
        " # reversing the arrays\n",
        "mealNoMealDataFrameArray = mealNoMealDataFrameArray[...,::-1]\n",
        "\n",
        "#removing the first column of the array since it holds some NaN values\n",
        "mealNoMealDataFrameArray = mealNoMealDataFrameArray[:,1:]\n",
        "mealNoMealDataFrame = pd.DataFrame(mealNoMealDataFrameArray)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N41ArSFWQX6q"
      },
      "source": [
        "(row, col) = mealNoMealDataFrame.shape\n",
        "    \n",
        "#Appending the label rows for the given data frame. it will be arranged in the following type\n",
        "labelColumn = [0,0,0,0,0,1,1,1,1,1] * (int(row/10)+1)\n",
        "labelColumn = labelColumn[0:row]\n",
        "mealNoMealDataFrame['label'] = labelColumn\n",
        "mealNoMealDataFrameArray = mealNoMealDataFrame.to_numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljVqCDZmQbol"
      },
      "source": [
        "#removing null values\n",
        "nanValueMapping = np.argwhere(np.isnan(mealNoMealDataFrameArray))\n",
        "rowsToBeDeleted = np.unique(nanValueMapping[:,0])\n",
        "mealNoMealDataFrameArray = np.delete(mealNoMealDataFrameArray,rowsToBeDeleted,0)\n",
        "mealNoMealDataFrame = pd.DataFrame(mealNoMealDataFrameArray)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyI31MGkQeal"
      },
      "source": [
        "labelColumn = mealNoMealDataFrame[[30]]\n",
        "mealNoMealDataFrame = mealNoMealDataFrame.drop(labels=30,axis=1)\n",
        "row, col = np.shape(mealNoMealDataFrameArray)\n",
        "\n",
        "mealNoMealDataFrameArray = mealNoMealDataFrame.to_numpy()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGgWOhWnQh1D"
      },
      "source": [
        "#Matrix to store all the derived features\n",
        "featureMatrix = pd.DataFrame()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krI2YClSQk6W"
      },
      "source": [
        "#Expanding Window Statistics\n",
        "tempFrame = pd.DataFrame(mealNoMealDataFrameArray)\n",
        "expandingWindow = tempFrame.expanding(min_periods=2, axis=1).mean()\n",
        "featureMatrix = pd.concat([expandingWindow.mean(axis=1),expandingWindow.min(axis=1), expandingWindow.max(axis=1),\n",
        "(expandingWindow.max(axis=1) - expandingWindow.min(axis=1))/2, expandingWindow.kurtosis(axis=1)], axis=1)\n",
        "featureMatrix.columns = ['exp_row_mean', 'exp_row_min', 'exp_row_max', 'exp_min_max_average', 'kurtosis'] "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPwng4vdQoBz"
      },
      "source": [
        "#Skewness and Standard-Deviation\n",
        "skewAndStdFrame = pd.DataFrame()\n",
        "\n",
        "tempFrame = pd.DataFrame(mealNoMealDataFrameArray)\n",
        "skewAndStdFrame = pd.concat([tempFrame.skew(skipna=True, axis=1), tempFrame.std(skipna=True, axis=1)], axis=1)\n",
        "skewAndStdFrame.columns = ['std','skewness']\n",
        "featureMatrix = pd.concat([featureMatrix, skewAndStdFrame], axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u36abpkrQrOc"
      },
      "source": [
        "#Finding moving average\n",
        "cgmMovingAverage = pd.DataFrame(mealNoMealDataFrameArray)\n",
        "window = 7 #for Every 35 minutes\n",
        "movingAverage = pd.DataFrame()\n",
        "rowVal, colVal = cgmMovingAverage.shape\n",
        "\n",
        "for i in range(0,colVal-window,window):\n",
        "  featureMatrix['mean_'+str((i/window)*35+35)+'min'] = cgmMovingAverage.iloc[:,i:i+window].mean(axis = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGK51DaiQuis"
      },
      "source": [
        "#Finding Windowed velocity\n",
        "window  = 6 #Taking the velocity for every half hour window\n",
        "cgmWindowVelocity = pd.DataFrame()\n",
        "\n",
        "row, col = mealNoMealDataFrameArray.shape\n",
        "mealNoMealDataFrameArray = pd.DataFrame(mealNoMealDataFrameArray)\n",
        "for i in range(0,col-window):\n",
        "    cgmWindowVelocity['moving_velocity_'+str(i)] = mealNoMealDataFrameArray[:][i+window]-mealNoMealDataFrameArray[:][i]\n",
        "featureMatrix['max_window_velocity'] = cgmWindowVelocity.max(axis = 1, skipna=True) "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0PoLia-Qx28",
        "outputId": "11f6aa5e-fb01-4723-9718-e254dba7caee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "#Entropy\n",
        "def get_entropy(series):\n",
        "    series_counts = series.value_counts()\n",
        "    entropy = scipy.stats.entropy(series_counts)  \n",
        "    return entropy\n",
        "\n",
        "featureMatrix['Entropy'] = mealNoMealDataFrameArray.apply(lambda row: get_entropy(row), axis=1) \n",
        "featureMatrix.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>exp_row_mean</th>\n",
              "      <th>exp_row_min</th>\n",
              "      <th>exp_row_max</th>\n",
              "      <th>exp_min_max_average</th>\n",
              "      <th>kurtosis</th>\n",
              "      <th>std</th>\n",
              "      <th>skewness</th>\n",
              "      <th>mean_35.0min</th>\n",
              "      <th>mean_70.0min</th>\n",
              "      <th>mean_105.0min</th>\n",
              "      <th>mean_140.0min</th>\n",
              "      <th>max_window_velocity</th>\n",
              "      <th>Entropy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120.950146</td>\n",
              "      <td>100.500000</td>\n",
              "      <td>152.866667</td>\n",
              "      <td>26.183333</td>\n",
              "      <td>-1.289162</td>\n",
              "      <td>0.125173</td>\n",
              "      <td>42.233124</td>\n",
              "      <td>101.000000</td>\n",
              "      <td>126.428571</td>\n",
              "      <td>164.000000</td>\n",
              "      <td>201.428571</td>\n",
              "      <td>39.0</td>\n",
              "      <td>3.123939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>133.969924</td>\n",
              "      <td>117.500000</td>\n",
              "      <td>142.766667</td>\n",
              "      <td>12.633333</td>\n",
              "      <td>-1.083193</td>\n",
              "      <td>-0.098956</td>\n",
              "      <td>14.075372</td>\n",
              "      <td>123.714286</td>\n",
              "      <td>152.000000</td>\n",
              "      <td>143.285714</td>\n",
              "      <td>149.857143</td>\n",
              "      <td>42.0</td>\n",
              "      <td>2.921658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>282.762645</td>\n",
              "      <td>275.333333</td>\n",
              "      <td>290.000000</td>\n",
              "      <td>7.333333</td>\n",
              "      <td>-0.776861</td>\n",
              "      <td>-0.325407</td>\n",
              "      <td>11.033908</td>\n",
              "      <td>284.857143</td>\n",
              "      <td>284.142857</td>\n",
              "      <td>273.571429</td>\n",
              "      <td>265.000000</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2.811796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>124.901270</td>\n",
              "      <td>111.000000</td>\n",
              "      <td>133.366667</td>\n",
              "      <td>11.183333</td>\n",
              "      <td>0.044570</td>\n",
              "      <td>-0.201047</td>\n",
              "      <td>10.720536</td>\n",
              "      <td>120.571429</td>\n",
              "      <td>127.285714</td>\n",
              "      <td>136.000000</td>\n",
              "      <td>144.714286</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3.042845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>139.395841</td>\n",
              "      <td>136.090909</td>\n",
              "      <td>147.033333</td>\n",
              "      <td>5.471212</td>\n",
              "      <td>0.342019</td>\n",
              "      <td>1.053647</td>\n",
              "      <td>12.968086</td>\n",
              "      <td>136.857143</td>\n",
              "      <td>137.285714</td>\n",
              "      <td>144.857143</td>\n",
              "      <td>161.714286</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2.794355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   exp_row_mean  exp_row_min  ...  max_window_velocity   Entropy\n",
              "0    120.950146   100.500000  ...                 39.0  3.123939\n",
              "1    133.969924   117.500000  ...                 42.0  2.921658\n",
              "2    282.762645   275.333333  ...                 10.0  2.811796\n",
              "3    124.901270   111.000000  ...                 16.0  3.042845\n",
              "4    139.395841   136.090909  ...                 28.0  2.794355\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S4RvSRuQ1QY"
      },
      "source": [
        "#Removed few features which eventually increases accuracy\n",
        "featureMatrix=featureMatrix.drop('mean_140.0min',axis=1)\n",
        "featureMatrix=featureMatrix.drop('exp_min_max_average',axis=1)\n",
        "featureMatrix=featureMatrix.drop('mean_105.0min',axis=1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3dcU6fqQ4hJ"
      },
      "source": [
        "#removing Nan row values if any\n",
        "featureMatrix = featureMatrix.dropna()\n",
        "\n",
        "y = labelColumn\n",
        "X = featureMatrix\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCK3PmWwQ8QX",
        "outputId": "4e772601-419a-4d99-a87d-7cb2e5032447",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#RandomForestClassifier\n",
        "RandomForestClassifier(X,y,X_train,X_test,y_train,y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************** RandomForestClassifier ***************\n",
            "[[34  6]\n",
            " [ 8 38]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.85      0.83        40\n",
            "         1.0       0.86      0.83      0.84        46\n",
            "\n",
            "    accuracy                           0.84        86\n",
            "   macro avg       0.84      0.84      0.84        86\n",
            "weighted avg       0.84      0.84      0.84        86\n",
            "\n",
            "0.8372093023255814\n",
            "KFold Scores [0.5813953488372093, 0.6941176470588235, 0.611764705882353, 0.6470588235294118, 0.7647058823529411]\n",
            "Kfold Mean Score --> 0.6598084815321477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZBM_JItQ_UC",
        "outputId": "1568d8fb-15ba-40aa-a064-1f6634a99812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#DecisionTreeClassifier\n",
        "DecisionTreeClassifier(X,y,X_train,X_test,y_train,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************** DecisionTreeClassifier ***************\n",
            "[[21 19]\n",
            " [16 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.57      0.53      0.55        40\n",
            "         1.0       0.61      0.65      0.63        46\n",
            "\n",
            "    accuracy                           0.59        86\n",
            "   macro avg       0.59      0.59      0.59        86\n",
            "weighted avg       0.59      0.59      0.59        86\n",
            "\n",
            "0.5930232558139535\n",
            "KFold Scores [0.6046511627906976, 0.611764705882353, 0.611764705882353, 0.611764705882353, 0.7058823529411765]\n",
            "Kfold Mean Score --> 0.6291655266757866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7R8DCj6REx6",
        "outputId": "92a837b4-976c-43aa-9548-f12bf4f5d492",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#MultiLayerPerceptron\n",
        "MultiLayerPerceptron(X,y,X_train,X_test,y_train,y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************** MultiLayerPerceptron ***************\n",
            "[[25 15]\n",
            " [17 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.60      0.62      0.61        40\n",
            "         1.0       0.66      0.63      0.64        46\n",
            "\n",
            "    accuracy                           0.63        86\n",
            "   macro avg       0.63      0.63      0.63        86\n",
            "weighted avg       0.63      0.63      0.63        86\n",
            "\n",
            "0.627906976744186\n",
            "KFold Scores [0.5813953488372093, 0.6823529411764706, 0.5647058823529412, 0.611764705882353, 0.7411764705882353]\n",
            "Kfold Mean Score --> 0.6362790697674419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSozWr2XRIDY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}